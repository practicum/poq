

In chapter UUU, a number of common SQL pitfalls were listed and described.  Most experienced SQL practicioners are aware of these pitfalls.  Being aware of the potential errors, however, does not make a person immune to accidentally committing them in the future.  While writing code in any language, coders are certainly influenced by knowledge of potential trouble-spots.  Once coding is finished, knowledge of trouble-spots can have an even bigger payoff during code reviews, testing, and debugging.  It is rare for a software project to achieve full test coverage; most project teams do not even attempt it.  In light of this, heuristics such as lists of common pitfalls become valuable guideposts so that testing efforts are focused on the pieces of code and the combinations of inputs that are most likely to uncover problems. (whether the 'list of pitfalls' explicitly documented or subconsciouly internalized by experienced teams) .

Imagine that we have a body of relational SQL code, we have an awareness of several pitfalls the code may have failed to correctly avoid, and we are now tasked with testing whether the code steers clear of the pitfalls or not.  What options are available for performing such testing?  Manual inspection is one possibility.  This is time consuming and error prone.  Running the code against one or more populated databases is another option.  To do so, some technique must be devised for populating the test database.  The database must also be dropped and regenerated and populated in several different ways in order to check that the SQL code is well-behaved in a variety of possible settings.  Tools exist for generating test data to populate test databases.  In general, however, such data generation tools are not "query aware."  This means that test data is populated into tables without regard to how the tables are actually queried.  Because of that, a table may be dropped and repopulated many times without ever creating a query-specific condition that would reveal a bug in a particular query.  In the absense of an off-the-shelf query-aware data generator, some ad-hoc script could be written to fulfill the same goal.  For example, if we have reason to doubt that a query will yield the desired outcome specifically when one given table is empty and another three tables are non-empty, then we must write a script to generate a populated test database meeting that particular criterion.

None of the testing options just described is ideal.  Given a SQL query and a suspected weakness of the query, it would be ideal to have a simple and succint way to input both the query and the suspected weakness into an automated system, and quickly obtain a yes/no answer as to whether the suspected flaw is truly present or not.  In other words, the query and the flaw are both known, so the best tool possible would be a tool that takes these two known pieces and automatically outputs "confirmed flawed" or "confirmed free of targeted flaw."

The main argument of this thesis is that such a tool is possible.  In this chapter a thorough high-level design for such a tool is proposed.  Rather than repeatedly employing phrases such as "the proposed tool" throughout this chapter, the tool is given the name POQ.  POQ is an acronym for Postconditions On Queries.  An automated implementation of POQ has not yet been completed.  Its intended future architecture will be outlined here.  Also, the operations that POQ will one day perform automatically have been performed manually and will be described in detail.  Despite the fact that POQ is currently only a hypothetical tool, giving the tool a proper name is merited for several reasons.  One (as stated earlier), awkward noun phrases -- such as "some future tool like the one proposed here" -- can be avoided whenever POQ is the subject of discussion.  Two, the author intends to pursue development of a full-featured implementation of POQ.  Therefore, using the tool's proper name in this paper will ensure that the identify of the future POQ tool is clearly linked back to this thesis.  Three, focusing discussion around the name of the ongoing POQ development project emphasizes that this research is heavily oriented towards producing practical outcomes with concrete applicability in the present day.

As stated previously, POQ's role is to process two inputs and produce a pass/fail result.  The two inputs were referred to as a SQL query and a suspected flaw.  By its inherent nature, a SQL query is already formatted suitably to be considered machine-readable input.  Therefore, to design the aforementioned ideal tool, the ambiguous piece of the design is that a format must be found for encoding a suspected flaw.  The format to be used in this chapter will be FOL formulas expressed in Prolog syntax.

The previous discussion was couched in terms of software testing.  However, it was made evident earlier that this thesis deals principally with verification.  Hopefully it is becoming apparent now that in the realm of relational SQL code, verification and testing are not necessarily too far separated from one another.  Relational SQL is declarative.  It is difficult to think of what it would mean to "test a declaration" without relying on formal analysis in one form or another.  If a SQL query is taken as a logical formula, then the natural tests to perform are satisfiability and validity tests.  Representing a "suspected flaw" using FOL formulas is really the act of creating a formally-specified post-condition.  The only difference is whether negation is applied.

For example, a suspected flaw might involve ____.  In FOL, we need to represent " a ___  ____."  One way would look like this:  .  Taking the point of view of formal verification, the corresponding postcondition would express that " a ___ *never* ____s."  The poscondition specifies the correct behavior of the SQL code.  The encoding of the flaw describes a corresponding incorrect behavior.  One is the negation of the other.

----------

The pitfalls described in chapter UUU were all demonstrated using (on average) only about two base tables.  Admittedly, when only two tables participate in a query, manual inspection can indeed be an effective and efficient method for error-checking.  In this chapter, as well, examples are presented using as few tables and as few columns as possible.

relational queries can be much larger (in practice)
tables can be of much greater arity (in practice)
DDL is not always kept close at hand while coding (in practice)
SQL operators often imply an on-the-fly generation of numerous 'virtual tables' while generating the final resultset.

----------

Figure JJJ illustrates several fundamental points about the high-level architecture of POQ and a sort of high-level 'call graph' showing how various modules call each other inside the system. ______. (if architecture is a 'static' kind of thing, the fill-in-the-blank word is supposed to be something dynamic, like 'dataflow')


